{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "05759be0-978f-4356-a39c-72df9085cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4a2c41f-158d-425c-9a10-a0997e349dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'email', 'sexe', 'image', 'username', 'city', 'state', 'country',\n",
      "       'date_embauche', 'Nom_Prenom', 'year', 'secteur_d_activite',\n",
      "       'etat_civile', 'type_contrat', 'age', 'niveau_education', 'salaire',\n",
      "       'profit'],\n",
      "      dtype='object')\n",
      "count      474.000000\n",
      "mean     65881.898734\n",
      "std      15057.736084\n",
      "min      32470.000000\n",
      "25%      54048.500000\n",
      "50%      66331.500000\n",
      "75%      77829.750000\n",
      "max      96566.000000\n",
      "Name: profit, dtype: float64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Charger les données\n",
    "df = pd.read_csv('data_final.csv')\n",
    "\n",
    "# Afficher les colonnes du DataFrame\n",
    "print(df.columns)\n",
    "\n",
    "# Vérifiez la colonne 'profit'\n",
    "if 'profit' not in df.columns:\n",
    "    raise ValueError(\"La colonne 'profit' est manquante dans le DataFrame.\")\n",
    "\n",
    "# Assurez-vous que la colonne 'profit' est de type numérique\n",
    "df['profit'] = pd.to_numeric(df['profit'], errors='coerce')\n",
    "\n",
    "# Vérifiez les valeurs après conversion\n",
    "print(df['profit'].describe())\n",
    "print(df['profit'].isnull().sum())  # Compte les valeurs manquantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "06e4403d-d3cf-4fcd-bdc3-6cd13064cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmployeeEnv(gym.Env):\n",
    "    def __init__(self, data):\n",
    "        super(EmployeeEnv, self).__init__()\n",
    "        \n",
    "        self.data = data.select_dtypes(include=[np.number])  # Sélection des colonnes numériques\n",
    "        self.num_employees = len(data)\n",
    "        self.action_space = spaces.Discrete(3)  # 0: conserver, 1: embaucher, 2: licencier\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(self.data.shape[1],), dtype=np.float32)\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.total_profit = 0.0\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.total_profit = 0.0\n",
    "        return self._get_observation()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        observation = self.data.iloc[self.current_step].values\n",
    "        max_value = np.max(observation)  # Ne convertit pas en float, car déjà numérique\n",
    "        return observation / max_value if max_value > 0 else observation\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        done = False\n",
    "        \n",
    "        if action == 1:  # Embaucher\n",
    "            reward = self.data.iloc[self.current_step]['profit']  # Récompense basée sur le profit\n",
    "            self.total_profit += reward\n",
    "        elif action == 2:  # Licencier\n",
    "            reward = -self.data.iloc[self.current_step]['profit']  # Pénalité pour licenciement\n",
    "            self.total_profit += reward\n",
    "            \n",
    "        self.current_step += 1\n",
    "        \n",
    "        if self.current_step >= self.num_employees:\n",
    "            done = True  # Fin de l'épisode\n",
    "\n",
    "        next_state = self._get_observation() if not done else np.zeros(self.observation_space.shape)\n",
    "        return next_state, reward, done, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb75f272-7519-41a4-a545-424104eece3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReinforcedAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = []\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_shape=(self.state_size,), activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        state = state.reshape(1, -1)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "    minibatch = random.sample(self.memory, batch_size)\n",
    "    for state, action, reward, next_state, done in minibatch:\n",
    "        target = reward\n",
    "        if not done:\n",
    "            next_state_reshaped = next_state.reshape(1, -1)\n",
    "            print(\"Next State Shape:\", next_state_reshaped.shape)  # Débogage\n",
    "            target += self.gamma * np.amax(self.model.predict(next_state_reshaped)[0])\n",
    "        state_reshaped = state.reshape(1, -1)\n",
    "        target_f = self.model.predict(state_reshaped)\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(state_reshaped, target_f, epochs=1, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "68d5cfe1-1805-43cb-ad28-d60650b614e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohamed\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "  0%|                                                                                         | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "object __array__ method not producing an array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(agent\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m32\u001b[39m:\n\u001b[1;32m---> 17\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m>\u001b[39m agent\u001b[38;5;241m.\u001b[39mepsilon_min:\n\u001b[0;32m     20\u001b[0m     agent\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mepsilon_decay\n",
      "Cell \u001b[1;32mIn[76], line 36\u001b[0m, in \u001b[0;36mReinforcedAgent.replay\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     34\u001b[0m target \u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m---> 36\u001b[0m     target \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mamax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     37\u001b[0m target_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(state\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     38\u001b[0m target_f[\u001b[38;5;241m0\u001b[39m][action] \u001b[38;5;241m=\u001b[39m target\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: object __array__ method not producing an array"
     ]
    }
   ],
   "source": [
    "# Boucle principale pour l'entraînement\n",
    "if __name__ == \"__main__\":\n",
    "    env = EmployeeEnv(data=df)\n",
    "    agent = ReinforcedAgent(state_size=len(env.data.columns), action_size=env.action_space.n)\n",
    "\n",
    "    episodes = 1000\n",
    "    for e in tqdm(range(episodes)):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "\n",
    "        if len(agent.memory) > 32:\n",
    "            agent.replay(32)\n",
    "\n",
    "        if agent.epsilon > agent.epsilon_min:\n",
    "            agent.epsilon *= agent.epsilon_decay\n",
    "\n",
    "    print(\"Entraînement terminé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88a84f3e-2b5c-48a6-88eb-494bb879a38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 474 entries, 0 to 473\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               474 non-null    object\n",
      " 1   address          474 non-null    object\n",
      " 2   email            474 non-null    object\n",
      " 3   first_name       474 non-null    object\n",
      " 4   gender           474 non-null    object\n",
      " 5   last_name        474 non-null    object\n",
      " 6   phone            474 non-null    object\n",
      " 7   picture          474 non-null    object\n",
      " 8   post_code        474 non-null    object\n",
      " 9   registered_date  474 non-null    object\n",
      " 10  username         474 non-null    object\n",
      "dtypes: object(11)\n",
      "memory usage: 40.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dee751c2-f600-47c7-8761-0e988d6e61f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          id  \\\n",
      "count                                    474   \n",
      "unique                                   474   \n",
      "top     cdb37f24-a06d-4588-8e28-d5f53f05ddf0   \n",
      "freq                                       1   \n",
      "\n",
      "                                            address                    email  \\\n",
      "count                                           474                      474   \n",
      "unique                                          467                      467   \n",
      "top     7965 Skogstien, Herøysund, Nordland, Norway  kayla.ulset@example.com   \n",
      "freq                                              6                        6   \n",
      "\n",
      "       first_name gender last_name     phone  \\\n",
      "count         474    474       474       474   \n",
      "unique        400      2       393       467   \n",
      "top         Kayla   male     Ulset  20631605   \n",
      "freq            6    251         6         6   \n",
      "\n",
      "                                                  picture post_code  \\\n",
      "count                                                 474       474   \n",
      "unique                                                175       465   \n",
      "top     https://randomuser.me/api/portraits/med/women/...      5082   \n",
      "freq                                                    7         7   \n",
      "\n",
      "                 registered_date         username  \n",
      "count                        474              474  \n",
      "unique                       467              467  \n",
      "top     2018-10-21T06:27:58.212Z  happyostrich348  \n",
      "freq                           6                6  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1a135bd-bbb8-471b-8f36-2f757d686544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'email', 'sexe', 'image', 'username', 'city', 'state', 'country',\n",
      "       'date_embauche', 'Nom_Prenom', 'year', 'secteur_d_activite',\n",
      "       'etat_civile', 'type_contrat', 'age', 'niveau_education', 'salaire',\n",
      "       'profit'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv('data_final.csv')\n",
    "\n",
    "# Afficher les colonnes du DataFrame\n",
    "print(df.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
